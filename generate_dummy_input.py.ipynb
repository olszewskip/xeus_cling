{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"generate_dummy_input.py\"\n",
    "import random\n",
    "\n",
    "#\n",
    "gpu_tile_width = 100\n",
    "cpu_tile_width = 13\n",
    "is_fat_interesting_region_present = 1\n",
    "number_of_lean_regions = 3\n",
    "column_and_bucket_counts = \"\"\"\n",
    "4 4\n",
    "2 5\n",
    "1 6\n",
    "117 2\n",
    "9886 2\n",
    "30 4\n",
    "30 5\n",
    "30 6\n",
    "200 2\n",
    "\"\"\"\n",
    "row_count = 1000\n",
    "#\n",
    "\n",
    "\n",
    "with open(\"dummy_gpu_tile_width.txt\", \"w\") as output_file:\n",
    "        output_file.write(str(gpu_tile_width))\n",
    "        \n",
    "with open(\"dummy_cpu_tile_width.txt\", \"w\") as output_file:\n",
    "        output_file.write(str(cpu_tile_width))\n",
    "\n",
    "with open(\"dummy_is_fat_interesting_region_present.txt\", \"w\") as output_file:\n",
    "        output_file.write(str(is_fat_interesting_region_present))\n",
    "        \n",
    "with open(\"dummy_number_of_lean_regions.txt\", \"w\") as output_file:\n",
    "        output_file.write(str(number_of_lean_regions))\n",
    "\n",
    "column_and_bucket_counts = \\\n",
    "[tuple(map(int, column_and_bucket_count.split())) \\\n",
    " for column_and_bucket_count in column_and_bucket_counts.strip().split(\"\\n\")]\n",
    "\n",
    "with open(\"dummy_column_and_bucket_counts.csv\", \"w\") as output_file:\n",
    "    for column_count, bucket_count in column_and_bucket_counts:\n",
    "        output_file.write(f\"{column_count},{bucket_count}\\n\")\n",
    "\n",
    "consequtive_bucket_counts =\\\n",
    "[bucket_count \\\n",
    " for column_count, bucket_count in column_and_bucket_counts \\\n",
    " for _ in range(column_count)]\n",
    "\n",
    "data = []\n",
    "\n",
    "for _ in range(row_count):\n",
    "    row = []\n",
    "    for bucket_count in consequtive_bucket_counts:\n",
    "        row.append(random.randint(0, bucket_count - 1))\n",
    "    data.append(row)\n",
    "    \n",
    "for column_index in range(len(data[0])):\n",
    "    column_values = set(data[row_index][column_index] for row_index in range(row_count))\n",
    "    assert column_values.issubset(range(consequtive_bucket_counts[column_index]))\n",
    "\n",
    "with open(\"dummy_discrete_data.csv\", \"w\") as output_file:\n",
    "    for row in data:\n",
    "        output_file.write(\",\".join(map(str, row)))\n",
    "        output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
